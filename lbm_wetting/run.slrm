#!/usr/bin/zsh

### Task name
#SBATCH --account=rwth1711
#SBATCH --job-name=two-phase_lbm

### Output file
#SBATCH --output=/hpcwork/fw641779/lbm/Toray-120C/55cov/structure0/two-phase_lbm.%J.out

### Ask for less than 4 GB memory per (CPU) task = MPI rank
#SBATCH --mem-per-cpu=2000

### Start a parallel job for a distributed-memory system on several nodes
#SBATCH --nodes=1

### For MPI, use one task per CPU
#SBATCH --cpus-per-task=1

### Number of processes per node (48 cores per node)
#SBATCH --ntasks-per-node=48

### Mail notification configuration
#SBATCH --mail-type=ALL
#SBATCH --mail-user=florian.wiesner@avt.rwth-aachen.de

### create time series
##SBATCH --array=1-100%1

### Maximum runtime
#SBATCH --time=24:00:00

module purge
module load GCC/11.3.0
module load OpenMPI/4.1.4

palabos_dir="/home/fw641779/Coding/lattice-boltzmann-wetting/mplbm-ut-mirror/src/2-phase_LBM/ShanChen"

config_file="/home/fw641779/Coding/lattice-boltzmann-wetting/lbm_wetting/twophase.yml"
sim_dir="/hpcwork/fw641779/lbm/Toray-120C/55cov/structure0"
sim_name="test_run"

conda activate lbm
python3 /home/fw641779/Coding/lattice-boltzmann-wetting/lbm_wetting/2_phase_sim.py $config_file $sim_dir $sim_name
return_code=$?
if [ $return_code -ne 0 ]; then
    echo "Python script failed with code $return_code. Exiting..."
    return $return_code
else
    # Else continue
    input_file=$sim_dir/$sim_name/input/2_phase_sim_input.xml
    $MPIEXEC $FLAGS_MPI_BATCH $palabos_dir $input_file
fi
