#!/usr/bin/zsh

### Task name
#SBATCH --account=rwth1711
#SBATCH --job-name=two-phase_lbm

### Output file
#SBATCH --output=/hpcwork/fw641779/lbm/output_logs/two-phase_lbm_%j.out

### Ask for less than 2625 MiB memory per (CPU) task = MPI rank
## Can be increased if larger partitions are used
#SBATCH --mem-per-cpu=2625

### Start a parallel job for a distributed-memory system on several nodes
#SBATCH --nodes=1

### Number of tasks (MPI ranks)
#SBATCH --ntasks=48

### Partition
#SBATCH --partition=c23ms

### Mail notification configuration
#SBATCH --mail-type=ALL
#SBATCH --mail-user=florian.wiesner@avt.rwth-aachen.de

### Maximum runtime per task
#SBATCH --time=24:00:00
##SBATCH --time=00:30:00

### create time series, i.e. 100 jobs one after another. Each runs for 24 hours
##SBATCH --array=1-100%1
### use nodes exclusively, only needed for larger simulations
##SBATCH --exclusive

module purge
module load GCC/11.3.0
module load OpenMPI/4.1.4

palabos_dir="/home/fw641779/Coding/lattice-boltzmann-wetting/mplbm-ut-mirror/src/2-phase_LBM/ShanChen"

config_file="/home/fw641779/Coding/lattice-boltzmann-wetting/lbm_wetting/twophase.yml"
# sim_dir="/hpcwork/fw641779/lbm/Test_PorousMedia"
sim_dir="/hpcwork/fw641779/lbm/Toray-120C/55cov/structure0"
sim_name="test_run"

# Make sure to activate the conda environment before running the script
export CONDA_ROOT=$HOME/miniconda3
source $CONDA_ROOT/etc/profile.d/conda.sh
export PATH="$CONDA_ROOT/bin:$PATH"
conda activate lbm
python /home/fw641779/Coding/lattice-boltzmann-wetting/lbm_wetting/2_phase_prep.py $config_file $sim_dir $sim_name

return_code=$?
if [ $return_code -ne 0 ]; then
    echo "Python script failed with code $return_code. Exiting..."
    exit $return_code
else
    # Else continue
    input_file=$sim_dir/$sim_name/input/2_phase_sim_input.xml
    $MPIEXEC $FLAGS_MPI_BATCH $palabos_dir $input_file
    # mpirun -np 4 $palabos_dir $input_file
fi
